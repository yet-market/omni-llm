# Omni-LLM Environment Configuration Template
# ==============================================
# Copy this file to .env and fill in your actual values
# Never commit .env files to version control!

# ======================
# AWS Configuration
# ======================
AWS_REGION=eu-west-2
AWS_PROFILE=yet

# ======================
# LLM Provider API Keys
# ======================
# Leave empty to use AWS Secrets Manager in production
# Fill in for local development only

# OpenAI API Key - Get from https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic API Key - Get from https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Mistral AI API Key - Get from https://console.mistral.ai/
MISTRAL_API_KEY=

# Cohere API Key - Get from https://dashboard.cohere.ai/
COHERE_API_KEY=

# Groq API Key - Get from https://console.groq.com/
GROQ_API_KEY=

# ======================
# Google Cloud Configuration
# ======================
GOOGLE_PROJECT_ID=
GOOGLE_LOCATION=us-central1
# For local development, set path to service account JSON file:
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# ======================
# Vector Store Configuration
# ======================

# Pinecone Configuration
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=us-east1-gcp

# OpenSearch Serverless
OPENSEARCH_ENDPOINT=
OPENSEARCH_REGION=eu-west-2

# Chroma Configuration (if using external instance)
CHROMA_HOST=localhost
CHROMA_PORT=8000

# Weaviate Configuration
WEAVIATE_URL=
WEAVIATE_API_KEY=

# Qdrant Configuration
QDRANT_URL=
QDRANT_API_KEY=

# ======================
# S3 Configuration for RAG
# ======================
S3_BUCKET_NAME=
S3_REGION=eu-west-2
S3_PREFIX=documents/

# ======================
# Application Configuration
# ======================
LOG_LEVEL=INFO
CACHE_TTL=3600
MAX_TOKENS_DEFAULT=4096
TEMPERATURE_DEFAULT=0.7
ENABLE_STREAMING=true
ENABLE_FUNCTION_CALLING=true

# ======================
# Security & Rate Limiting
# ======================
API_KEY_VALIDATION=true
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000
ALLOWED_ORIGINS=*
MAX_REQUEST_SIZE_MB=10

# ======================
# Development Configuration
# ======================
# For local development only - use simple API keys
OMNI_LLM_API_KEYS=dev-key-12345,test-key-67890

# ======================
# AWS Secrets Manager (Production)
# ======================
# These are used in production instead of direct API keys
API_KEYS_SECRET_NAME=omni-llm/api-keys
LLM_PROVIDERS_SECRET_NAME=omni-llm/providers

# ======================
# MCP Configuration
# ======================
MCP_TIMEOUT=30
MCP_MAX_RETRIES=3
MCP_SERVER_REGISTRY_URL=

# ======================
# Performance Tuning
# ======================
CONNECTION_POOL_SIZE=20
REQUEST_TIMEOUT=300
LAMBDA_MEMORY_MB=1024
LAMBDA_TIMEOUT_SECONDS=900

# ======================
# Monitoring & Observability
# ======================
ENABLE_XRAY_TRACING=true
ENABLE_METRICS=true
METRICS_NAMESPACE=OmniLLM
ALERT_EMAIL=

# ======================
# Cost Management
# ======================
COST_TRACKING_ENABLED=true
COST_ALERT_THRESHOLD_USD=100
PREFERRED_PROVIDERS=openai,anthropic,groq
FALLBACK_PROVIDERS=openai,anthropic

# ======================
# Custom Provider Support
# ======================
# JSON format for custom providers
CUSTOM_PROVIDER_ENDPOINTS={}
CUSTOM_PROVIDER_HEADERS={}
CUSTOM_PROVIDER_AUTH_TOKENS={}