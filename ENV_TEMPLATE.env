# Omni-LLM Environment Variables Template
# Copy this file to .env and fill in your API keys and configurations

# ======================
# LLM Provider API Keys
# ======================

# OpenAI API Key - Get from https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# Anthropic API Key - Get from https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-...

# Mistral AI API Key - Get from https://console.mistral.ai/
MISTRAL_API_KEY=...

# Cohere API Key - Get from https://dashboard.cohere.ai/
COHERE_API_KEY=...

# Groq API Key - Get from https://console.groq.com/
GROQ_API_KEY=gsk_...

# Google Vertex AI Configuration
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
GOOGLE_PROJECT_ID=your-gcp-project-id
GOOGLE_LOCATION=us-central1

# ======================
# AWS Configuration
# ======================

# AWS Region for Bedrock and other services
AWS_REGION=us-east-1
AWS_BEDROCK_REGION=us-east-1

# ======================
# Vector Store Configuration
# ======================

# Pinecone Configuration
PINECONE_API_KEY=...
PINECONE_ENVIRONMENT=us-east1-gcp

# OpenSearch Serverless
OPENSEARCH_ENDPOINT=https://...amazonaws.com
OPENSEARCH_REGION=us-east-1

# Chroma Configuration (if using external instance)
CHROMA_HOST=localhost
CHROMA_PORT=8000

# Weaviate Configuration
WEAVIATE_URL=https://...weaviate.network
WEAVIATE_API_KEY=...

# Qdrant Configuration
QDRANT_URL=https://...qdrant.io
QDRANT_API_KEY=...

# ======================
# S3 Configuration for RAG
# ======================

S3_BUCKET_NAME=your-documents-bucket
S3_REGION=us-east-1
S3_PREFIX=knowledge-base/

# ======================
# Application Configuration
# ======================

LOG_LEVEL=INFO
CACHE_TTL=3600
MAX_TOKENS_DEFAULT=4096
TEMPERATURE_DEFAULT=0.7
ENABLE_STREAMING=true
ENABLE_FUNCTION_CALLING=true

# ======================
# Security & Rate Limiting
# ======================

API_KEY_VALIDATION=true
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000
ALLOWED_ORIGINS=*
MAX_REQUEST_SIZE_MB=10

# ======================
# MCP Configuration
# ======================

MCP_TIMEOUT=30
MCP_MAX_RETRIES=3
MCP_SERVER_REGISTRY_URL=

# ======================
# Performance Tuning
# ======================

CONNECTION_POOL_SIZE=20
REQUEST_TIMEOUT=300
LAMBDA_MEMORY_MB=1024
LAMBDA_TIMEOUT_SECONDS=900

# ======================
# Monitoring & Observability
# ======================

ENABLE_XRAY_TRACING=true
ENABLE_METRICS=true
METRICS_NAMESPACE=OmniLLM
ALERT_EMAIL=admin@yourdomain.com

# ======================
# Cost Management
# ======================

COST_TRACKING_ENABLED=true
COST_ALERT_THRESHOLD_USD=100
PREFERRED_PROVIDERS=openai,anthropic,groq
FALLBACK_PROVIDERS=openai,anthropic

# ======================
# Custom Provider Support
# ======================

# JSON format for custom providers
CUSTOM_PROVIDER_ENDPOINTS={}
CUSTOM_PROVIDER_HEADERS={}
CUSTOM_PROVIDER_AUTH_TOKENS={}